{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/e2kk2e/datatool/blob/main/Kopie_von_create_zip_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "def create_project_zip():\n",
        "    zip_filename = \"ProcureIntel_Complete_Kit.zip\"\n",
        "\n",
        "    # File contents definitions\n",
        "    files = {\n",
        "        # --- Root Configs ---\n",
        "        \"package.json\": \"\"\"{\n",
        "  \"name\": \"procurement-radar-api\",\n",
        "  \"version\": \"0.1.0\",\n",
        "  \"main\": \"src/index.js\",\n",
        "  \"scripts\": {\n",
        "    \"start\": \"node src/index.js\",\n",
        "    \"dev\": \"nodemon src/index.js\",\n",
        "    \"db:migrate\": \"node database/migrate.js\"\n",
        "  },\n",
        "  \"dependencies\": {\n",
        "    \"express\": \"^4.18.2\",\n",
        "    \"pg\": \"^8.11.3\",\n",
        "    \"axios\": \"^1.6.2\",\n",
        "    \"node-cron\": \"^3.0.3\",\n",
        "    \"dotenv\": \"^16.3.1\",\n",
        "    \"cors\": \"^2.8.5\",\n",
        "    \"helmet\": \"^7.1.0\"\n",
        "  },\n",
        "  \"devDependencies\": {\n",
        "    \"nodemon\": \"^3.0.1\"\n",
        "  }\n",
        "}\"\"\",\n",
        "        \"docker-compose.yml\": \"\"\"version: '3.8'\n",
        "\n",
        "services:\n",
        "  api:\n",
        "    build: .\n",
        "    ports:\n",
        "      - \"3000:3000\"\n",
        "    environment:\n",
        "      - NODE_ENV=development\n",
        "      - DATABASE_URL=postgres://user:password@db:5432/procurement_radar\n",
        "      - PORT=3000\n",
        "    depends_on:\n",
        "      - db\n",
        "    command: >\n",
        "      sh -c \"npm run db:migrate && npm run dev\"\n",
        "    volumes:\n",
        "      - .:/app\n",
        "      - /app/node_modules\n",
        "\n",
        "  db:\n",
        "    image: postgres:15-alpine\n",
        "    environment:\n",
        "      POSTGRES_USER: user\n",
        "      POSTGRES_PASSWORD: password\n",
        "      POSTGRES_DB: procurement_radar\n",
        "    ports:\n",
        "      - \"5432:5432\"\n",
        "    volumes:\n",
        "      - pgdata:/var/lib/postgresql/data\n",
        "\n",
        "volumes:\n",
        "  pgdata:\n",
        "\"\"\",\n",
        "        \"Dockerfile\": \"\"\"FROM node:20-alpine\n",
        "WORKDIR /app\n",
        "COPY package*.json ./\n",
        "RUN npm ci --only=production\n",
        "COPY . .\n",
        "EXPOSE 3000\n",
        "ENV NODE_ENV=production\n",
        "ENV PORT=3000\n",
        "CMD [\"npm\", \"start\"]\n",
        "\"\"\",\n",
        "        \"cloudbuild.yaml\": \"\"\"steps:\n",
        "  # 1. Build\n",
        "  - name: 'gcr.io/cloud-builders/docker'\n",
        "    args: ['build', '-t', 'europe-west3-docker.pkg.dev/$PROJECT_ID/procurement-repo/api:$COMMIT_SHA', '-t', 'europe-west3-docker.pkg.dev/$PROJECT_ID/procurement-repo/api:latest', '.']\n",
        "\n",
        "  # 2. Push\n",
        "  - name: 'gcr.io/cloud-builders/docker'\n",
        "    args: ['push', 'europe-west3-docker.pkg.dev/$PROJECT_ID/procurement-repo/api:$COMMIT_SHA']\n",
        "\n",
        "  # 3. Migrate DB\n",
        "  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n",
        "    entrypoint: gcloud\n",
        "    args:\n",
        "      - 'run'\n",
        "      - 'jobs'\n",
        "      - 'execute'\n",
        "      - 'migrate-job'\n",
        "      - '--region=europe-west3'\n",
        "      - '--wait'\n",
        "\n",
        "  # 4. Deploy\n",
        "  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'\n",
        "    entrypoint: gcloud\n",
        "    args:\n",
        "      - 'run'\n",
        "      - 'deploy'\n",
        "      - 'procurement-api'\n",
        "      - '--image=europe-west3-docker.pkg.dev/$PROJECT_ID/procurement-repo/api:$COMMIT_SHA'\n",
        "      - '--region=europe-west3'\n",
        "      - '--platform=managed'\n",
        "      - '--allow-unauthenticated'\n",
        "\n",
        "images:\n",
        "  - 'europe-west3-docker.pkg.dev/$PROJECT_ID/procurement-repo/api:$COMMIT_SHA'\n",
        "  - 'europe-west3-docker.pkg.dev/$PROJECT_ID/procurement-repo/api:latest'\n",
        "\"\"\",\n",
        "\n",
        "        # --- Source Code ---\n",
        "        \"src/index.js\": \"\"\"require('dotenv').config();\n",
        "const express = require('express');\n",
        "const cors = require('cors');\n",
        "const helmet = require('helmet');\n",
        "const logger = require('./config/logger');\n",
        "\n",
        "// Import routes\n",
        "const tendersRoutes = require('./api/routes/tenders');\n",
        "const analyticsRoutes = require('./api/routes/analytics');\n",
        "\n",
        "const app = express();\n",
        "const PORT = process.env.PORT || 3000;\n",
        "\n",
        "app.use(helmet());\n",
        "app.use(cors());\n",
        "app.use(express.json());\n",
        "\n",
        "// Routes\n",
        "app.use('/api/tenders', tendersRoutes);\n",
        "app.use('/api/analytics', analyticsRoutes);\n",
        "\n",
        "app.get('/health', (req, res) => {\n",
        "  res.json({ status: 'ok', service: 'procurement-radar' });\n",
        "});\n",
        "\n",
        "app.listen(PORT, () => {\n",
        "  logger.info(`Server running on port ${PORT}`);\n",
        "});\n",
        "\"\"\",\n",
        "        \"src/config/logger.js\": \"\"\"const logger = {\n",
        "  info: (msg, meta) => console.log(`[INFO] ${msg}`, meta || ''),\n",
        "  error: (msg, meta) => console.error(`[ERROR] ${msg}`, meta || ''),\n",
        "  debug: (msg, meta) => {\n",
        "    if (process.env.NODE_ENV !== 'production') {\n",
        "      console.log(`[DEBUG] ${msg}`, meta || '');\n",
        "    }\n",
        "  }\n",
        "};\n",
        "module.exports = logger;\n",
        "\"\"\",\n",
        "        \"src/config/database.js\": \"\"\"const { Pool } = require('pg');\n",
        "const logger = require('./logger');\n",
        "\n",
        "const pool = new Pool({ connectionString: process.env.DATABASE_URL });\n",
        "\n",
        "module.exports = {\n",
        "  query: async (text, params) => {\n",
        "    const start = Date.now();\n",
        "    try {\n",
        "      const res = await pool.query(text, params);\n",
        "      const duration = Date.now() - start;\n",
        "      logger.debug('executed query', { text, duration, rows: res.rowCount });\n",
        "      return res;\n",
        "    } catch (err) {\n",
        "        logger.error('query error', { text, err });\n",
        "        throw err;\n",
        "    }\n",
        "  },\n",
        "  pool\n",
        "};\n",
        "\"\"\",\n",
        "        \"src/api/routes/tenders.js\": \"\"\"const express = require('express');\n",
        "const router = express.Router();\n",
        "const db = require('../../config/database');\n",
        "\n",
        "// GET /api/tenders\n",
        "router.get('/', async (req, res) => {\n",
        "  try {\n",
        "    const { region, cpv, limit = 20, offset = 0 } = req.query;\n",
        "\n",
        "    let query = `\n",
        "      SELECT id, source_id, source, title, cpv_codes, authority_name, estimated_value, deadline_date\n",
        "      FROM tenders\n",
        "      WHERE status = 'active'\n",
        "    `;\n",
        "    const params = [];\n",
        "    let paramCount = 1;\n",
        "\n",
        "    if (region) {\n",
        "      query += ` AND region = $${paramCount}`;\n",
        "      params.push(region);\n",
        "      paramCount++;\n",
        "    }\n",
        "\n",
        "    if (cpv) {\n",
        "      query += ` AND $${paramCount} = ANY(cpv_codes)`;\n",
        "      params.push(cpv);\n",
        "      paramCount++;\n",
        "    }\n",
        "\n",
        "    query += ` ORDER BY publication_date DESC LIMIT $${paramCount} OFFSET $${paramCount + 1}`;\n",
        "    params.push(limit, offset);\n",
        "\n",
        "    const result = await db.query(query, params);\n",
        "\n",
        "    res.json({ success: true, count: result.rows.length, data: result.rows });\n",
        "  } catch (err) {\n",
        "    console.error(err);\n",
        "    res.status(500).json({ error: 'Database error' });\n",
        "  }\n",
        "});\n",
        "\n",
        "// GET /api/tenders/:id\n",
        "router.get('/:id', async (req, res) => {\n",
        "  try {\n",
        "    const { id } = req.params;\n",
        "    const result = await db.query('SELECT * FROM tenders WHERE id = $1', [id]);\n",
        "\n",
        "    if (result.rows.length === 0) {\n",
        "      return res.status(404).json({ error: 'Tender not found' });\n",
        "    }\n",
        "\n",
        "    res.json({ success: true, data: result.rows[0] });\n",
        "  } catch (err) {\n",
        "    res.status(500).json({ error: 'Server error' });\n",
        "  }\n",
        "});\n",
        "\n",
        "module.exports = router;\n",
        "\"\"\",\n",
        "        \"src/api/routes/analytics.js\": \"\"\"const express = require('express');\n",
        "const router = express.Router();\n",
        "const db = require('../../config/database');\n",
        "\n",
        "router.get('/market-share', async (req, res) => {\n",
        "  try {\n",
        "    const query = `\n",
        "      SELECT winner_name, COUNT(*) as win_count, SUM(award_value) as total_volume\n",
        "      FROM awards\n",
        "      WHERE award_date > NOW() - INTERVAL '1 year'\n",
        "      GROUP BY winner_name\n",
        "      ORDER BY total_volume DESC\n",
        "      LIMIT 10\n",
        "    `;\n",
        "    const result = await db.query(query);\n",
        "    res.json({ success: true, data: result.rows });\n",
        "  } catch (err) {\n",
        "    res.status(500).json({ error: 'Analytics error' });\n",
        "  }\n",
        "});\n",
        "\n",
        "module.exports = router;\n",
        "\"\"\",\n",
        "\n",
        "        # --- Database ---\n",
        "        \"database/migrate.js\": \"\"\"require('dotenv').config();\n",
        "const fs = require('fs');\n",
        "const path = require('path');\n",
        "const { Pool } = require('pg');\n",
        "\n",
        "const pool = new Pool({ connectionString: process.env.DATABASE_URL });\n",
        "\n",
        "async function migrate() {\n",
        "  console.log('Starting migration...');\n",
        "  const schemaPath = path.join(__dirname, 'schema.sql');\n",
        "  const schema = fs.readFileSync(schemaPath, 'utf8');\n",
        "\n",
        "  const client = await pool.connect();\n",
        "  try {\n",
        "    await client.query(schema);\n",
        "    console.log('Schema applied successfully.');\n",
        "  } catch (err) {\n",
        "    console.error('Migration failed:', err);\n",
        "  } finally {\n",
        "    client.release();\n",
        "    pool.end();\n",
        "  }\n",
        "}\n",
        "\n",
        "migrate();\n",
        "\"\"\",\n",
        "        \"database/schema.sql\": \"\"\"-- Users\n",
        "CREATE TABLE IF NOT EXISTS users (\n",
        "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
        "    email VARCHAR(255) UNIQUE NOT NULL,\n",
        "    password_hash VARCHAR(255) NOT NULL,\n",
        "    api_key VARCHAR(64) UNIQUE,\n",
        "    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n",
        ");\n",
        "\n",
        "-- Tenders\n",
        "CREATE TABLE IF NOT EXISTS tenders (\n",
        "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
        "    source_id VARCHAR(255) NOT NULL,\n",
        "    source VARCHAR(50) NOT NULL,\n",
        "    title TEXT NOT NULL,\n",
        "    description TEXT,\n",
        "    cpv_codes TEXT[],\n",
        "    authority_name VARCHAR(255),\n",
        "    region VARCHAR(100),\n",
        "    estimated_value DECIMAL(15, 2),\n",
        "    publication_date DATE,\n",
        "    deadline_date TIMESTAMP WITH TIME ZONE,\n",
        "    status VARCHAR(50) DEFAULT 'active',\n",
        "    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,\n",
        "    UNIQUE(source, source_id)\n",
        ");\n",
        "\n",
        "-- Awards\n",
        "CREATE TABLE IF NOT EXISTS awards (\n",
        "    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),\n",
        "    tender_id UUID REFERENCES tenders(id),\n",
        "    winner_name VARCHAR(255),\n",
        "    award_value DECIMAL(15, 2),\n",
        "    award_date DATE,\n",
        "    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP\n",
        ");\n",
        "\"\"\",\n",
        "\n",
        "        # --- Terraform ---\n",
        "        \"terraform/main.tf\": \"\"\"terraform {\n",
        "  required_providers {\n",
        "    google = { source = \"hashicorp/google\", version = \">= 4.0\" }\n",
        "  }\n",
        "}\n",
        "\n",
        "provider \"google\" {\n",
        "  project = var.project_id\n",
        "  region  = var.region\n",
        "}\n",
        "\n",
        "resource \"google_project_service\" \"apis\" {\n",
        "  for_each = toset([\"run.googleapis.com\", \"sqladmin.googleapis.com\", \"artifactregistry.googleapis.com\", \"cloudbuild.googleapis.com\", \"secretmanager.googleapis.com\"])\n",
        "  service = each.key\n",
        "  disable_on_destroy = false\n",
        "}\n",
        "\n",
        "resource \"google_artifact_registry_repository\" \"repo\" {\n",
        "  location = var.region\n",
        "  repository_id = \"procurement-repo\"\n",
        "  format = \"DOCKER\"\n",
        "  depends_on = [google_project_service.apis]\n",
        "}\n",
        "\n",
        "resource \"google_sql_database_instance\" \"main\" {\n",
        "  name = \"procurement-db-${random_id.db_suffix.hex}\"\n",
        "  database_version = \"POSTGRES_15\"\n",
        "  region = var.region\n",
        "  deletion_protection = false\n",
        "  settings {\n",
        "    tier = \"db-f1-micro\"\n",
        "    availability_type = \"ZONAL\"\n",
        "    ip_configuration { ipv4_enabled = true }\n",
        "  }\n",
        "  depends_on = [google_project_service.apis]\n",
        "}\n",
        "\n",
        "resource \"random_id\" \"db_suffix\" { byte_length = 4 }\n",
        "\n",
        "resource \"google_sql_database\" \"database\" {\n",
        "  name = \"procurement_radar\"\n",
        "  instance = google_sql_database_instance.main.name\n",
        "}\n",
        "\n",
        "resource \"google_sql_user\" \"users\" {\n",
        "  name = var.db_user\n",
        "  instance = google_sql_database_instance.main.name\n",
        "  password = var.db_password\n",
        "}\n",
        "\n",
        "resource \"google_secret_manager_secret\" \"db_url\" {\n",
        "  secret_id = \"DATABASE_URL\"\n",
        "  replication { auto {} }\n",
        "  depends_on = [google_project_service.apis]\n",
        "}\n",
        "\n",
        "resource \"google_secret_manager_secret_version\" \"db_url_val\" {\n",
        "  secret = google_secret_manager_secret.db_url.id\n",
        "  secret_data = \"postgres://${google_sql_user.users.name}:${var.db_password}@/procurement_radar?host=/cloudsql/${google_sql_database_instance.main.connection_name}\"\n",
        "}\n",
        "\n",
        "resource \"google_service_account\" \"app_sa\" {\n",
        "  account_id = \"procurement-app-sa\"\n",
        "}\n",
        "\n",
        "resource \"google_project_iam_member\" \"sql_client\" {\n",
        "  project = var.project_id\n",
        "  role = \"roles/cloudsql.client\"\n",
        "  member = \"serviceAccount:${google_service_account.app_sa.email}\"\n",
        "}\n",
        "\n",
        "resource \"google_secret_manager_secret_iam_member\" \"secret_access\" {\n",
        "  secret_id = google_secret_manager_secret.db_url.id\n",
        "  role = \"roles/secretmanager.secretAccessor\"\n",
        "  member = \"serviceAccount:${google_service_account.app_sa.email}\"\n",
        "}\n",
        "\n",
        "resource \"google_cloud_run_v2_service\" \"default\" {\n",
        "  name = \"procurement-api\"\n",
        "  location = var.region\n",
        "  ingress = \"INGRESS_TRAFFIC_ALL\"\n",
        "  template {\n",
        "    service_account = google_service_account.app_sa.email\n",
        "    containers {\n",
        "      image = \"europe-west3-docker.pkg.dev/${var.project_id}/procurement-repo/api:latest\"\n",
        "      env {\n",
        "        name = \"NODE_ENV\"\n",
        "        value = \"production\"\n",
        "      }\n",
        "      env {\n",
        "        name = \"DATABASE_URL\"\n",
        "        value_source {\n",
        "          secret_key_ref {\n",
        "            secret = google_secret_manager_secret.db_url.secret_id\n",
        "            version = \"latest\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      volume_mounts {\n",
        "        name = \"cloudsql\"\n",
        "        mount_path = \"/cloudsql\"\n",
        "      }\n",
        "    }\n",
        "    volumes {\n",
        "      name = \"cloudsql\"\n",
        "      cloud_sql_instance {\n",
        "        instances = [google_sql_database_instance.main.connection_name]\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  depends_on = [google_project_service.apis]\n",
        "  lifecycle {\n",
        "    ignore_changes = [template[0].containers[0].image]\n",
        "  }\n",
        "}\n",
        "\n",
        "resource \"google_cloud_run_v2_job\" \"migrate\" {\n",
        "  name = \"migrate-job\"\n",
        "  location = var.region\n",
        "  template {\n",
        "    template {\n",
        "      service_account = google_service_account.app_sa.email\n",
        "      containers {\n",
        "        image = \"europe-west3-docker.pkg.dev/${var.project_id}/procurement-repo/api:latest\"\n",
        "        command = [\"npm\", \"run\", \"db:migrate\"]\n",
        "        env {\n",
        "          name = \"DATABASE_URL\"\n",
        "          value_source {\n",
        "            secret_key_ref {\n",
        "              secret = google_secret_manager_secret.db_url.secret_id\n",
        "              version = \"latest\"\n",
        "            }\n",
        "          }\n",
        "        }\n",
        "        volume_mounts {\n",
        "          name = \"cloudsql\"\n",
        "          mount_path = \"/cloudsql\"\n",
        "        }\n",
        "      }\n",
        "      volumes {\n",
        "        name = \"cloudsql\"\n",
        "        cloud_sql_instance {\n",
        "          instances = [google_sql_database_instance.main.connection_name]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\"\"\",\n",
        "        \"terraform/variables.tf\": \"\"\"variable \"project_id\" {\n",
        "  type = string\n",
        "}\n",
        "variable \"region\" {\n",
        "  type = string\n",
        "  default = \"europe-west3\"\n",
        "}\n",
        "variable \"db_user\" {\n",
        "  type = string\n",
        "  default = \"radar_admin\"\n",
        "}\n",
        "variable \"db_password\" {\n",
        "  type = string\n",
        "  sensitive = true\n",
        "}\n",
        "\"\"\"\n",
        "    }\n",
        "\n",
        "    # Write files to zip\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "        for file_path, content in files.items():\n",
        "            zipf.writestr(file_path, content)\n",
        "\n",
        "    print(f\"Created {zip_filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    create_project_zip()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "pM5njFJZ2axq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('GEMINI_API_KEY')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "35yYf1ko3H4T",
        "outputId": "39912749-323d-43f8-9063-27b2aaa42622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AQ.Ab8RN6JEcExdmSx3eVFyrmhGShuv-Y1Gl2P2Qa0cMtTXWVDWdw'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdd15f0a"
      },
      "source": [
        "# Task\n",
        "Create the `src/services/collector.js` module to handle data ingestion. The module should:\n",
        "\n",
        "1.  Import `axios` and the database pool from `../config/database`.\n",
        "2.  Implement a `collectData` function that fetches tender data from a placeholder URL (e.g., \"https://api.example.com/tenders\").\n",
        "3.  Normalize the data and insert it into the `tenders` table (handling duplicates via `ON CONFLICT` on `source` and `source_id`).\n",
        "4.  If award data is present, insert it into the `awards` table.\n",
        "5.  Export the `collectData` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7b4fe07"
      },
      "source": [
        "## Implement Data Ingestion Service\n",
        "\n",
        "### Subtask:\n",
        "Create the `src/services/collector.js` module to handle fetching, normalizing, and storing tender data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e41e6593"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask requires creating a new directory and a JavaScript file for the data ingestion service. I will use Python's `os` module to create the directory and file I/O to write the specified content into `src/services/collector.js`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9261f97c",
        "outputId": "1c70eb96-c38a-4336-f7e6-9a123647f24c"
      },
      "source": [
        "import os\n",
        "\n",
        "# Ensure the services directory exists\n",
        "os.makedirs('src/services', exist_ok=True)\n",
        "\n",
        "# Define the content for src/services/collector.js\n",
        "collector_js_content = \"\"\"const axios = require('axios');\n",
        "const db = require('../config/database');\n",
        "\n",
        "const collectData = async () => {\n",
        "  try {\n",
        "    // Fetch data from placeholder URL\n",
        "    const response = await axios.get('https://api.example.com/tenders');\n",
        "    const items = response.data;\n",
        "\n",
        "    for (const item of items) {\n",
        "      // Insert into tenders table\n",
        "      const query = `\n",
        "        INSERT INTO tenders (\n",
        "          source_id, source, title, cpv_codes, authority_name,\n",
        "          region, estimated_value, publication_date, deadline_date\n",
        "        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)\n",
        "        ON CONFLICT (source, source_id)\n",
        "        DO UPDATE SET\n",
        "          title = EXCLUDED.title,\n",
        "          updated_at = NOW()\n",
        "        RETURNING id\n",
        "      `;\n",
        "\n",
        "      const values = [\n",
        "        item.source_id,\n",
        "        item.source || 'api',\n",
        "        item.title,\n",
        "        item.cpv_codes,\n",
        "        item.authority_name,\n",
        "        item.region,\n",
        "        item.estimated_value,\n",
        "        item.publication_date,\n",
        "        item.deadline_date\n",
        "      ];\n",
        "\n",
        "      const result = await db.query(query, values);\n",
        "      const tenderId = result.rows[0].id;\n",
        "\n",
        "      // Insert Award if present\n",
        "      if (item.award) {\n",
        "        const awardQuery = `\n",
        "          INSERT INTO awards (tender_id, winner_name, award_value, award_date)\n",
        "          VALUES ($1, $2, $3, $4)\n",
        "        `;\n",
        "        await db.query(awardQuery, [\n",
        "          tenderId,\n",
        "          item.award.winner_name,\n",
        "          item.award.award_value,\n",
        "          item.award.award_date\n",
        "        ]);\n",
        "      }\n",
        "    }\n",
        "    console.log(`Processed ${items.length} items successfully.`);\n",
        "  } catch (error) {\n",
        "    console.error('Error in data collection:', error);\n",
        "  }\n",
        "};\n",
        "\n",
        "module.exports = { collectData };\n",
        "\"\"\"\n",
        "\n",
        "# Write the file\n",
        "with open('src/services/collector.js', 'w') as f:\n",
        "    f.write(collector_js_content)\n",
        "\n",
        "print(\"Successfully created src/services/collector.js\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created src/services/collector.js\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9642b447"
      },
      "source": [
        "## Setup Scheduler\n",
        "\n",
        "### Subtask:\n",
        "Update `src/index.js` to import the collector service and schedule it to run periodically using `node-cron`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f0aa71d"
      },
      "source": [
        "**Reasoning**:\n",
        "Update `src/index.js` to include the `node-cron` scheduler and import the `collectData` service, then overwrite the file with the new content.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a3ab92a",
        "outputId": "2cf7670b-0296-4339-842d-e22d7092525b"
      },
      "source": [
        "index_js_content = \"\"\"require('dotenv').config();\n",
        "const express = require('express');\n",
        "const cors = require('cors');\n",
        "const helmet = require('helmet');\n",
        "const cron = require('node-cron');\n",
        "const logger = require('./config/logger');\n",
        "const { collectData } = require('./services/collector');\n",
        "\n",
        "// Import routes\n",
        "const tendersRoutes = require('./api/routes/tenders');\n",
        "const analyticsRoutes = require('./api/routes/analytics');\n",
        "\n",
        "const app = express();\n",
        "const PORT = process.env.PORT || 3000;\n",
        "\n",
        "app.use(helmet());\n",
        "app.use(cors());\n",
        "app.use(express.json());\n",
        "\n",
        "// Routes\n",
        "app.use('/api/tenders', tendersRoutes);\n",
        "app.use('/api/analytics', analyticsRoutes);\n",
        "\n",
        "app.get('/health', (req, res) => {\n",
        "  res.json({ status: 'ok', service: 'procurement-radar' });\n",
        "});\n",
        "\n",
        "// Schedule data collection every day at midnight\n",
        "cron.schedule('0 0 * * *', () => {\n",
        "  logger.info('Starting scheduled data collection');\n",
        "  collectData();\n",
        "});\n",
        "\n",
        "app.listen(PORT, () => {\n",
        "  logger.info(`Server running on port ${PORT}`);\n",
        "});\n",
        "\"\"\"\n",
        "\n",
        "with open('src/index.js', 'w') as f:\n",
        "    f.write(index_js_content)\n",
        "\n",
        "print(\"Successfully updated src/index.js with scheduler configuration.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully updated src/index.js with scheduler configuration.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}